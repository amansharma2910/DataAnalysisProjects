{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Reliance Stocks - EDA\n---\n\nIn this notebook, we will perform an EDA on the RELIANCE stock prices over an year's time from July-2019 to July-2020. We will try to observe some dominant and hidden trends in the data. Let us begin by importing all the project dependencies. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, ArtistAnimation\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Importing the Data\n---","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stocks_df = pd.read_csv('../input/reliance-stock-datajul-2019-jul-2020/Stock-Data-Reliance.csv')\nstocks_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Wrangling\n---\n\nIn this section, we will clean the dataset, removing all the unnecesary elements to prepare it for EDA.\n\nFirst, let us drop the 'Unnamed: 0) column.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stocks_df.drop(['Unnamed: 0'], axis = 1, inplace = True)\nstocks_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us now check column-wise the number of NaN values in the dataset. ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"null = pd.DataFrame(stocks_df.isnull().sum(axis = 0), columns = ['total null vals'])\nnull['percent_null'] = null['total null vals']/len(stocks_df)\nnull","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the total null values are less than 0.02% of the total data. However since stock data comprises of a time series, dropping the NaN data directly can result in losing some important data. So before we drop the data, let us first check the rows with the null values.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stocks_df[stocks_df.High.isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, dropping the rows with null values won't cause any data loss. So let us go ahead and drop these values.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stocks_df.dropna(axis = 0, inplace = True)\nstocks_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let us check the data type for each column in our dataframe.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"stocks_df.dtypes.to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here's where we observe some problems in our dataset. Firstly, the supposed numerical columnsâ€” **Open,High, Low, Close, Adj Close, Volume** are actually of the data-type object. This is due to the comma(,) as the thousands separator. So we need to convert these columns to numerical data. Also, we need to convert the **Date** column to date-time type. ","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# converting Date column to date-time format\nstocks_df.Date = pd.to_datetime(stocks_df.Date)\n\n\n# converting Open, High, Low, Close, Adj Close, Volume to floating points\ndef floatify(x):\n    try:\n        x = float(x.replace(',',''))\n    except:\n        x = np.nan\n    return x\n\ncols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n\nfor col in cols:\n    stocks_df[col] = stocks_df[col].apply(lambda x: floatify(x))\n\n# dropping the newly generated NaN values\nstocks_df.dropna(axis = 0, inplace = True)\nstocks_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the last step, let us reverse the dataframe so that the latest date is at the bottom. This step depends on one's preference. When showing plots, I prefer to show the latest data to the rightmost side.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# reversing the dataframe\nstocks_df = stocks_df.iloc[::-1]\n\n# resetting the index\nstocks_df.reset_index(drop=True, inplace=True)\n\nstocks_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n---\nNow that we have cleaned our data, let us now move ahead to the EDA part.\n\n**Let us first have a look at the overall performance of the RELIANCE stock.**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nfig,ax = plt.subplots(figsize = (16,8)) \nsns.lineplot(x = 'Date', y = 'Adj Close', data = stocks_df, ax = ax)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here are the observations from the above plot-\n* The stock price of RELIANCE rose quite steadily from July, 2019 to December, 2019, with slight ups and downs during this time.\n* Then, during the time period of January, 2020 to April, 2020, the price declined steeply, falling below INR1000. A primary reason for this can be the COVID-19 pandemic, which caused a standstill in the international and national markets.\n* After April, 2020, in a sudden turn of events, the prices began to rise suddenly. The primary reason for this increase in the stock price can be the Facebook's $5.7 billion in Reliance Jio. After that, the RELIANCE stock prices have been on a constant rise.\n\n---\n\n**Now, let us have a look at the monthly average price of the RELIANCE stock.** This will require some feature engineering, where we first will have to group the data by months then get the mean stock price for each month group. ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# extracting features from the given data\nstocks_df['month'] = pd.DatetimeIndex(stocks_df['Date']).month\nstocks_df['year'] = pd.DatetimeIndex(stocks_df['Date']).year\nstocks_df['day'] = pd.DatetimeIndex(stocks_df['Date']).day\nstocks_df['weekday'] = pd.DatetimeIndex(stocks_df['Date']).weekday\nstocks_df['Avg'] = (stocks_df.High + stocks_df.Low)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"monthly_data = stocks_df.groupby(['year', 'month'])\nmonth_list = []\nmean_price = []\nfor k,_ in monthly_data:\n    month = str(k[1]) + '-' + str(k[0])\n    month_list.append(month)\n    mean_price.append(monthly_data.get_group(k).mean()['Adj Close'])\n\nfig,ax = plt.subplots(figsize = (10, 8)) \nsns.barplot(y = month_list, x = mean_price, ax = ax)\nax.set_xlabel('Mean Adjusted Closing Price')\nax.set_ylabel('Month')\nax.set_title('AVERAGE STOCK PRICE PER MONTH')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few observations from the plot above:\n* The time duration from April, 2020 onwards seems to be a really good phase for RELIANCE, with the stock price on a continuous rise.\n* While the pandemic caused a dip in the share prices, RELIANCE managed to stay above an average of INR1000.\n\n---\nNow, let us view the daily price fluctuations for the RELIANCE stock price for a few months. By price fluctuations, we are referring to the price gap between the highest and lowest price of the stock for the day.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dailyPriceFluctuations(grouped_df, month, year):\n    data = grouped_df.get_group((year,month))\n    month_dict = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sept', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n    fig, ax = plt.subplots(figsize = (15,5))\n    sns.lineplot(x = 'day', y = 'High', marker = 'o', data = data, ax = ax)\n    sns.lineplot(x = 'day', y = 'Low', marker = 's', data = data, ax = ax)\n    ax.set_title('MONTH: ' + month_dict[month] + '-' + str(year))\n    ax.set_ylabel('Prices')\n    ax.set_xlabel('Day of Month')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# July, 2019\ndailyPriceFluctuations(monthly_data, month = 7, year = 2019)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# December, 2019\ndailyPriceFluctuations(monthly_data, month = 12, year = 2019)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A very interesting observation here. We can see the exact day the the RELIANCE stock prices started to experience the pandemic downfall, a period which continued for more than 3 months. As we can see from the graph above, the date was December 20, 2019. ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# March, 2020\ndailyPriceFluctuations(monthly_data, month = 3, year = 2020)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another interesting observation here. After a period of continuous downfall, it was aroung March 24, 2020 that the prices started to increase, continuing the trend steadinly for the following months.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# July, 2020\ndailyPriceFluctuations(monthly_data, month = 7, year = 2020)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's one another observation from the above plots. \n* In case of Jul-2020, while the stock prices were steadily increasing, the price fluctuations were not very significant.\n* on the other hand, in the month of Mar-2020, the prices were not steady, falling and rising unpredictably. Here, we can observe some significant price fluctuations.\n\nThis is a classic example of supply and demand. In the month of March, 2020, there was a lot of uncertainty in the markets. New buyers were looking into stepping into stock-market due to an all time low stock prices. Old buyers were selling stocks because of the fear of losing more money. This random trading caused a lot of fluctuations in the demand and supply of the stock prices. And this differece is evident in the RELIANCE stock price fluctuations.\n\nOn the other hand, the time period post Mar-2020 saw a steady rise in the price. Fresh investments from Facebook attracted the buyers. The demand increased steadily. And hence the lesser price fluctuations.\n\n---\nAfter seeing the plots, I had an interesting idea. Let us check which week days are the best to buy the RELIANCE stock, based on-\n1. Overall trends (An average for the entire data, comprising of both price rises and falls) \n2. Current trends (Current trends comprise of the period from April-July, 2020)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"days = np.array(['Mon', 'Tues', 'Wed', 'Thru', 'Fri'])\n\nfig, ax = plt.subplots(1, 4, figsize = (20, 4))\n\nweek_data = stocks_df.groupby(['weekday']).mean()\navg_daily = ((week_data.High + week_data.Low)/2).to_numpy()\nsns.barplot(x = days, y = avg_daily, ax = ax[0])\nax[0].set_ylim(1400, 1450)\nax[0].set_title('Average Daily Data')\n\napr_data = monthly_data.get_group((2020,4)).groupby(['weekday']).mean()\navg_daily = ((apr_data.High + apr_data.Low)/2).to_numpy()\nsns.barplot(x = days, y = avg_daily, ax = ax[1])\nax[1].set_ylim(1200, 1350)\nax[1].set_title('April-2020 Daily Data')\n\n\nmay_data = monthly_data.get_group((2020,5)).groupby(['weekday']).mean()\navg_daily = ((may_data.High + may_data.Low)/2).to_numpy()\nsns.barplot(x = days, y = avg_daily, ax = ax[2])\nax[2].set_ylim(1400, 1500)\nax[2].set_title('May-2020 Daily Data')\n\n\njun_data = monthly_data.get_group((2020,6)).groupby(['weekday']).mean()\navg_daily = ((jun_data.High + jun_data.Low)/2).to_numpy()\nsns.barplot(x = days, y = avg_daily, ax = ax[3])\nax[3].set_ylim(1600, 1680)\nax[3].set_title('June-2020 Daily Data')\n\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Awesome! Next time I'm buying RELIANCE stocks, I now know the best day to play the gamble is Wednesday.\n\n---\nNext, let us observe how the average stock price and the volume of commodities available are correlated. We will see the observations for:\n1. Overall trends (An average for the entire data, comprising of both price rises and falls over time)\n2. Current trends (Current trends comprise of the period from April-July, 2020)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"may_data = monthly_data.get_group((2020,5))\nvolume = may_data.Volume/100000\n\nfig, ax = plt.subplots(1, 4, figsize = (20, 4))\n\n\nvolume = stocks_df.Volume/100000\nsns.regplot(x = stocks_df['Avg'], y = volume, ax = ax[0])\nax[0].set_ylabel('Volume(1= 1e5)')\nax[0].set_title('Overall Data')\n\ndec_data = monthly_data.get_group((2019,12))\nvolume = dec_data.Volume/100000\nsns.regplot(x = dec_data['Avg'], y = volume, ax = ax[1])\nax[1].set_title('Dec-2019')\nax[1].set_ylabel('')\n\nmay_data = monthly_data.get_group((2020,5))\nvolume = may_data.Volume/100000\nsns.regplot(x = may_data['Avg'], y = volume, ax = ax[2])\nax[2].set_title('May-2020')\nax[2].set_ylabel('')\n\njun_data = monthly_data.get_group((2020,6))\nvolume = jun_data.Volume/100000\nsns.regplot(x = jun_data['Avg'], y = volume, ax = ax[3])\nax[3].set_title('Jun-2020')\nax[3].set_ylabel('')\n\n\nfig.show()\n# may_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations from the above plots:\n* It is evident the volume of comoditties has a very weak correlation with the average daily stock prices, almost 0 in case of the overall data.\n* If we observe the plot from May-2020, we see that the linear regression line shows a considerable correlation, however, if we observe the confidence interval (the shaded blue region), we see that the uncertainty is very large. This means that the estimated correlations value is wrong/uncertain.\n* These observation confirm that there is very weak correlation between the RELIANCE stock prices and the stock volume.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}